{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxTsvp26KTDKVPcwDLf5Mp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krupa049/Text-Generation/blob/main/text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2hxG3HzZyWy",
        "outputId": "9efea158-7def-4b81-ab81-0b9256f1bb0d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "G4IuzSNTUlqA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7uParICVj8X",
        "outputId": "c4b2c051-9947-4eb2-c878-23ba85f3dc24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
      ],
      "metadata": {
        "id": "S5zN9sy1WAnV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "50lm3IokWdPF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))"
      ],
      "metadata": {
        "id": "-BcUxzANWnmI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "aQVP17oyWyad"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3"
      ],
      "metadata": {
        "id": "yoc7QJTBXDdg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "next_characters = []\n",
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_characters.append(text[i + SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "12v4jKRhXW5m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)"
      ],
      "metadata": {
        "id": "HgzfItubaUrh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "    for t, character in enumerate(sentence):\n",
        "        x[i, t, char_to_index[character]] = 1\n",
        "    y[i, char_to_index[next_characters[i]]] = 1"
      ],
      "metadata": {
        "id": "tvAe9L4ibtTQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "Uuamfy0dcIOJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TEjj4rMces4",
        "outputId": "aba2e77b-cafb-4241-b0dc-838bd28e5a48"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThLJUjXlcuAl",
        "outputId": "b23f6545-ed7c-42ce-8bd1-0e11451b015d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 103s 155ms/step - loss: 2.7132\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 101s 155ms/step - loss: 2.3124\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 102s 156ms/step - loss: 2.1977\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 101s 155ms/step - loss: 2.1154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7949b4a9eb90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('textgenerator.model')"
      ],
      "metadata": {
        "id": "pkGCJAGMeo4X"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('textgenerator.model')"
      ],
      "metadata": {
        "id": "82xA-XqDfBy-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "Kh4l3NQwfLLv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, character in enumerate(sentence):\n",
        "            x[0, t, char_to_index[character]] = 1\n",
        "\n",
        "        predictions = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(predictions, temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "fUAo311EfjdF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('------------0.2-----------')\n",
        "print(generate_text(300, 0.2))\n",
        "print('------------0.4-----------')\n",
        "print(generate_text(300, 0.4))\n",
        "print('------------0.6-----------')\n",
        "print(generate_text(300, 0.6))\n",
        "print('------------0.8-----------')\n",
        "print(generate_text(300, 0.8))\n",
        "print('------------1.0-----------')\n",
        "print(generate_text(300, 1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuSbxzYzg0h5",
        "outputId": "a3181483-a5cd-4272-cb39-8c6fe813309c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------0.2-----------\n",
            "xford, to prevent the worst,\n",
            "forthwith whis be the hath heart the mand and the hard for the then the hand and and and and and and and and in the hard and the forthen the parenter the hare the mand and the hers and and and and and the sond and and the hing the mand\n",
            "and that the mand the fare to the shand and that the beather the ward and a\n",
            "------------0.4-----------\n",
            " love till now? forswear it, sight!\n",
            "for my the hing that and in the beath that shand and is the enesther and heres of that sing\n",
            "theall the herenthy wath sing wather soffrerest theer\n",
            "betare the beate and ast and in the here\n",
            "that wather forrencent,\n",
            "the start to the proung ast and my and that the and in thas sist of the sing\n",
            "there mistung to\n",
            "------------0.6-----------\n",
            "ld more care to keep\n",
            "than in possession sanger\n",
            "tofride\n",
            "tho gale and ard of ande,\n",
            "and linging hather mussed\n",
            "for beagen, and that noth hame thes fars toas thenes,\n",
            "and and menttofers for shent wath llother,\n",
            "ind which hand thath my and ond gondser,\n",
            "thin of the hure thate the locon!\n",
            "\n",
            "queicstand:\n",
            "what sourge to to and whoust hard,\n",
            "fore hors of \n",
            "------------0.8-----------\n",
            " hours will fair juliet wake:\n",
            "she will bist onderty thinglerloung tinn coussisond this steld,\n",
            "lat the what inefthet hengure?\n",
            "\n",
            "armile:\n",
            "hagn merand ashing is for noold than,\n",
            "nour hatr keng a goung or merey,\n",
            "of ter past and cimingend; youd teerwery,\n",
            "tong is tlist geassen thingen i charcure;\n",
            "and there palinghed; a dith worun thing for you han\n",
            "------------1.0-----------\n",
            " that interrupts him shall not live.\n",
            "\n",
            "kint cowansuien, that $oud hayry.\n",
            "\n",
            "leamen:\n",
            "i tith hederccannlf, inofeld woalt ho$.\n",
            "merence,\n",
            "to knigh, i ant lorsife;\n",
            "and thing\n",
            "tones th stle to lee; nome,\n",
            "\n",
            "achingout:\n",
            "whet, not yo; my bathes; whach'd hamveoras.\n",
            "\n",
            "bomen:\n",
            "ie, fare wirgar coment in mess groit\n",
            "\n",
            "h wet thele i wets binglans mewero.\n",
            "\n",
            "hati aiv\n"
          ]
        }
      ]
    }
  ]
}